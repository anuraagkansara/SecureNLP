{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuraagkansara/SecureNLP/blob/master/19jan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EgT3t-0-E32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngn26HhHazdZ",
        "colab_type": "code",
        "outputId": "09fb9999-69ad-4bf6-d80f-0e48b4e43a8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/anuraagkansara/SecureNLP.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SecureNLP' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JveutA7fA1DV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "fe569afd-6158-4666-80ac-4da60cf93862"
      },
      "source": [
        "!pip install glove_python"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting glove_python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/79/7e7e548dd9dcb741935d031117f4bed133276c2a047aadad42f1552d1771/glove_python-0.1.0.tar.gz (263kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 17.6MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 122kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 133kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 143kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 153kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 163kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 174kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 184kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 194kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 204kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 215kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 225kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 235kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 245kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 256kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.4.1)\n",
            "Building wheels for collected packages: glove-python\n",
            "  Building wheel for glove-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glove-python: filename=glove_python-0.1.0-cp36-cp36m-linux_x86_64.whl size=700348 sha256=79779a99a28c18e9537b5cf536a1a147385a072ae01e888bf64f3dca7d5f5ca5\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/4b/6d/10c0d2ad32c9d9d68beec9694a6f0b6e83ab1662a90a089a4b\n",
            "Successfully built glove-python\n",
            "Installing collected packages: glove-python\n",
            "Successfully installed glove-python-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmcB2QVdkUKi",
        "colab_type": "code",
        "outputId": "97325e21-d849-44b5-9df4-257b4e2673cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz#egg=en_core_web_md==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IizMiNWDj9nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import spacy\n",
        "import nltk\n",
        "import sklearn\n",
        "# import pycrfsuite\n",
        "# from mosestokenizer import MosesDetokenizer\n",
        "from glove import Corpus, Glove\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from bs4 import BeautifulSoup\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llrXKWzT-K3V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def read_sentences(path, sentence_separator):\n",
        "    filenames = os.listdir(path)\n",
        "    result = []\n",
        "    for filename in filenames:\n",
        "        with open(path + filename) as file:\n",
        "            lines = file.read()\n",
        "        lines = lines.split(sentence_separator)[:-1]\n",
        "        for line in lines:\n",
        "            l = []\n",
        "            for x in line.splitlines():\n",
        "                w = x.split(' ')\n",
        "                if w[0] == \"''\":\n",
        "                    w[0] = '\"'\n",
        "                w[0] = w[0].lower()\n",
        "                if len(w) == 2:\n",
        "                    l.append(np.array(w))\n",
        "            l = np.array(l)\n",
        "            result.append(l)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdxlxCRvk6o3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = read_sentences(\"SecureNLP/train/tokenized/\", \" \\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Sz3Wrf8k8B5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = []\n",
        "for i in [1, 2, 3]:\n",
        "    test.extend(read_sentences(f\"SecureNLP/test_{i}/tokenized/\", \"\\n\\n\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EuxLdDik8KK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev = read_sentences(\"SecureNLP/dev/tokenized/\", \" \\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugaZbzaC_DzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"SecureNLP/train/additional_plaintext/\"\n",
        "filenames = os.listdir(PATH)\n",
        "additional_data = []\n",
        "for filename in filenames:\n",
        "    # print(filename)\n",
        "    with open(PATH + filename) as file:\n",
        "        lines = file.read()\n",
        "    soup = BeautifulSoup(lines, 'html.parser')\n",
        "    soup.get_text()\n",
        "    for section in soup.find_all('section'):\n",
        "        for section in section.contents:\n",
        "            if not str(section).startswith(\"<\") and str(section) != \"\\n\":\n",
        "                doc = nlp(str(section))\n",
        "                for sent in doc.sents:\n",
        "                    tmp = []\n",
        "                    for token in sent:\n",
        "                        if token.text and token.text not in (\"\\n\", \" \"):\n",
        "                            tmp.append(token.text.lower())\n",
        "                    additional_data.append(tmp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7gnLNit_DxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = [list(x[:, 0]) for x in train]\n",
        "train_y = [list(x[:, 1]) for x in train]\n",
        "\n",
        "test_x = [list(x[:, 0]) for x in test]\n",
        "test_y = [list(x[:, 1]) for x in test]\n",
        "\n",
        "dev_x = [list(x[:, 0]) for x in dev]\n",
        "dev_y = [list(x[:, 1]) for x in dev]\n",
        "\n",
        "embed = [list(x[:, 0]) for x in train]\n",
        "embed.extend(additional_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdF_kt-Q_Dup",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "f4bfd32e-5d12-4f4b-a4e2-d0f04ba60bac"
      },
      "source": [
        "corpus = Corpus() \n",
        "corpus.fit(embed, window=10)\n",
        "\n",
        "glove = Glove(no_components=100, learning_rate=0.05)\n",
        " \n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4DJG6oH_DsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_embodding(sentence):\n",
        "    sums = np.zeros(100)\n",
        "    for word in sentence:\n",
        "        try:\n",
        "            emb = glove.word_vectors[glove.dictionary[word]]\n",
        "        except KeyError:\n",
        "            emb = np.zeros(100)\n",
        "        sums += emb\n",
        "    return sums/len(sentence)\n",
        "def get_labels(tags):\n",
        "    if sum([tag == 'O' for tag in tags]) == len(tags):\n",
        "        return 0\n",
        "    return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_jxi5Hi_DnA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array([sentence_embodding(s) for s in train_x])\n",
        "y_train = np.array([get_labels(tags) for tags in train_y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKpwDS2DB8tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Oxo_ZgRk8HM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = np.array([sentence_embodding(s) for s in test_x])\n",
        "y_test = np.array([get_labels(tags) for tags in test_y])\n",
        "\n",
        "X_dev = np.array([sentence_embodding(s) for s in dev_x])\n",
        "y_dev = np.array([get_labels(tags) for tags in dev_y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb1uYaEJBqkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def labels_as_strings(vector_of_indices): \n",
        "    return ['irrelevant' if ind == 0 else 'relevant' for ind in vector_of_indices]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SNeffbIBqho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ac907257-b9d5-445b-800b-8165d4e4f4c9"
      },
      "source": [
        "# SMOTE\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train, y_train = sm.fit_resample(X_train, y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsiJE8Z4BqfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "6a360b40-b21d-4ca8-9369-ef50b5559cd3"
      },
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "print(log_reg.score(X_test, y_test))\n",
        "print(classification_report(labels_as_strings(y_test), labels_as_strings(log_reg.predict(X_test))))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, log_reg.predict(X_test)).ravel()\n",
        "print(\"true negative: \", tn)\n",
        "print(\"false positive: \", fp)\n",
        "print(\"false negative: \", fn)\n",
        "print(\"true positive: \", tp)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(log_reg.score(X_dev, y_dev))\n",
        "print(classification_report(labels_as_strings(y_dev), labels_as_strings(log_reg.predict(X_dev))))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_dev, log_reg.predict(X_dev)).ravel()\n",
        "print(\"true negative: \", tn)\n",
        "print(\"false positive: \", fp)\n",
        "print(\"false negative: \", fn)\n",
        "print(\"true positive: \", tp)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6672512056115739\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  irrelevant       0.96      0.65      0.78      2025\n",
            "    relevant       0.22      0.80      0.35       256\n",
            "\n",
            "    accuracy                           0.67      2281\n",
            "   macro avg       0.59      0.73      0.56      2281\n",
            "weighted avg       0.88      0.67      0.73      2281\n",
            "\n",
            "true negative:  1317\n",
            "false positive:  708\n",
            "false negative:  51\n",
            "true positive:  205\n",
            "\n",
            "\n",
            "\n",
            "0.763396537510305\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  irrelevant       0.99      0.76      0.86      1134\n",
            "    relevant       0.20      0.87      0.32        79\n",
            "\n",
            "    accuracy                           0.76      1213\n",
            "   macro avg       0.59      0.81      0.59      1213\n",
            "weighted avg       0.94      0.76      0.82      1213\n",
            "\n",
            "true negative:  857\n",
            "false positive:  277\n",
            "false negative:  10\n",
            "true positive:  69\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ldhdk1bBqcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfoZBj6bBqZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
