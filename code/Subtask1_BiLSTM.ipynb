{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bi-LSTM.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuraagkansara/SecureNLP/blob/master/code/Bi_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X16P30mAybc",
        "colab_type": "code",
        "outputId": "17ded9cf-523f-4577-e6ed-629a90bb8cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "!git clone https://github.com/anuraagkansara/SecureNLP.git\n",
        "!pip install glove_python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'SecureNLP' already exists and is not an empty directory.\n",
            "Requirement already satisfied: glove_python in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tVd7mTw8ckm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import time, random\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "#from lstm import LSTMSentiment\n",
        "from bilstm import BiLSTMSentiment\n",
        "from torchtext import data\n",
        "import numpy as np\n",
        "import argparse\n",
        "import codecs\n",
        "\n",
        "\n",
        "torch.set_num_threads(8)\n",
        "torch.manual_seed(1)\n",
        "random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA6oknk48eBv",
        "colab_type": "code",
        "outputId": "71e57e76-d3f7-424c-cb0e-3543016b0aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls\n",
        "# %tb\n",
        "# args = argparse.ArgumentParser()\n",
        "# args.add_argument('--m', dest='model', default='lstm', help='specify the mode to use (default: lstm)')\n",
        "# args = args.parse_args()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bilstm.py  dev.tsv  __pycache__  sample_data  SecureNLP  test.tsv  train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mv_0TU28tqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 8        # 20\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 150\n",
        "\n",
        "BATCH_SIZE = 5\n",
        "timestamp = str(int(time.time()))\n",
        "best_dev_acc = 0.0\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuorVm4Vm3o7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(truth, pred):\n",
        "    assert len(truth) == len(pred)\n",
        "    right = 0\n",
        "    for i in range(len(truth)):\n",
        "        if truth[i] == pred[i]:\n",
        "            right += 1.0\n",
        "    return right / len(truth)\n",
        "\n",
        "\n",
        "def train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch):\n",
        "    model.cuda(device)\n",
        "    loss_function.cuda(device)\n",
        "    model.train()\n",
        "    avg_loss = 0.0\n",
        "    truth_res = []\n",
        "    pred_res = []\n",
        "    count = 0\n",
        "    for batch in tqdm(train_iter, desc='Train epoch '+str(epoch+1)):\n",
        "        sent, label = batch.text, batch.label\n",
        "        sent = sent.to(device)\n",
        "        label = label.to(device)\n",
        "        label.data.sub_(1)\n",
        "        truth_res += list(label.data)\n",
        "        model.batch_size = len(label.data)\n",
        "        model.hidden = model.init_hidden()\n",
        "        pred = model(sent)\n",
        "        pred_label = pred.data.max(1)[1]\n",
        "        pred_res += [x for x in pred_label]\n",
        "        model.zero_grad()\n",
        "        loss = loss_function(pred, label)\n",
        "        avg_loss += loss.data\n",
        "        count += 1\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_loss /= len(train_iter)\n",
        "    acc = get_accuracy(truth_res, pred_res)\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "def train_epoch(model, train_iter, loss_function, optimizer):\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    avg_loss = 0.0\n",
        "    truth_res = []\n",
        "    pred_res = []\n",
        "    count = 0\n",
        "    for batch in train_iter:\n",
        "        sent, label = batch.text, batch.label\n",
        "        sent = sent.to(device)\n",
        "        label = label.to(device)\n",
        "        label.data.sub_(1)\n",
        "        truth_res += list(label.data)\n",
        "        model.batch_size = len(label.data)\n",
        "        model.hidden = model.init_hidden()\n",
        "        pred = model(sent)\n",
        "        pred_label = pred.cpu().data.max(1)[1].numpy()\n",
        "        pred_res += [x for x in pred_label]\n",
        "        model.zero_grad()\n",
        "        loss = loss_function(pred, label)\n",
        "        avg_loss += loss.data\n",
        "        count += 1\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    avg_loss /= len(train_iter)\n",
        "    acc = get_accuracy(truth_res, pred_res)\n",
        "    return avg_loss, acc\n",
        "\n",
        "\n",
        "def evaluate(model, data, loss_function, name):\n",
        "    model.cuda(device)\n",
        "    loss_function.cuda(device)\n",
        "    model.eval()\n",
        "    avg_loss = 0.0\n",
        "    truth_res = []\n",
        "    pred_res = []\n",
        "    for batch in data:\n",
        "        sent, label = batch.text, batch.label\n",
        "        sent = sent.to(device)\n",
        "        label = label.to(device)\n",
        "        label.data.sub_(1)\n",
        "        truth_res += list(label.data)\n",
        "        model.batch_size = len(label.data)\n",
        "        model.hidden = model.init_hidden()\n",
        "        pred = model(sent)\n",
        "        pred_label = pred.data.max(1)[1]\n",
        "        pred_res += [x for x in pred_label]\n",
        "        loss = loss_function(pred, label)\n",
        "        avg_loss += loss.data\n",
        "    avg_loss /= len(data)\n",
        "    acc = get_accuracy(truth_res, pred_res)\n",
        "    print(name + ': loss %.2f acc %.1f' % (avg_loss, acc*100))\n",
        "    return acc,pred_res,truth_res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfiWN7BvRMiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_bin_vec(fname, vocab):\n",
        "    \"\"\"\n",
        "    Loads 300x1 word vecs from Google (Mikolov) word2vec\n",
        "    \"\"\"\n",
        "    word_vecs = {}\n",
        "    with open(fname, \"rb\") as f:\n",
        "        header = f.readline()\n",
        "        vocab_size, layer1_size = map(int, header.split())\n",
        "        binary_len = np.dtype('float32').itemsize * layer1_size\n",
        "        for line in range(vocab_size):\n",
        "            word = []\n",
        "            while True:\n",
        "                ch = f.read(1).decode('latin-1')\n",
        "                if ch == ' ':\n",
        "                    word = ''.join(word)\n",
        "                    break\n",
        "                if ch != '\\n':\n",
        "                    word.append(ch)\n",
        "            if word in vocab:\n",
        "               word_vecs[word] = np.fromstring(f.read(binary_len), dtype='float32')\n",
        "            else:\n",
        "                f.read(binary_len)\n",
        "    return word_vecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIIpTl2J-QUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_sst(text_field, label_field, batch_size):\n",
        "    train, dev, test = data.TabularDataset.splits(path='/content/', train='train.tsv',\n",
        "                                                  validation='dev.tsv', test='test.tsv', format='tsv',\n",
        "                                                  fields=[('text', text_field), ('label', label_field)]\n",
        "                                                  )\n",
        "    text_field.build_vocab(train, dev, test)\n",
        "    label_field.build_vocab(train, dev, test)\n",
        "    # train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\n",
        "    #             batch_sizes=(batch_size, len(dev), len(test)), sort_key=lambda x: len(x.text), repeat=False, device=-1)\n",
        "    # for GPU run\n",
        "    train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\n",
        "                batch_sizes=(batch_size, len(dev), len(test)), sort_key=lambda x: len(x.text), repeat=False, device=None)\n",
        "    return train_iter, dev_iter, test_iter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMX53Atn9k9G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# devoce = torch.device('cuda')\n",
        "text_field = data.Field(lower=True)\n",
        "label_field = data.Field(sequential=False)\n",
        "train_iter, dev_iter, test_iter = load_sst(text_field, label_field, BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORg_nzo5-I8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " model = BiLSTMSentiment(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, vocab_size=len(text_field.vocab), label_size=len(label_field.vocab)-1,\\\n",
        "                          use_gpu=USE_GPU, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQF1q8qoa0zm",
        "colab_type": "code",
        "outputId": "429c6468-931f-4542-f393-359fae43c1af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if USE_GPU:\n",
        "    model = model.cuda()\n",
        "    print(\"Inside GPU\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inside GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODJaL6urHIXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print('Load word embeddings...')\n",
        "# # # glove\n",
        "# # text_field.vocab.load_vectors('glove.6B.100d')\n",
        "\n",
        "# # word2vector\n",
        "# word_to_idx = text_field.vocab.stoi\n",
        "# print(type(word_to_idx))\n",
        "#pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(text_field.vocab), 300))\n",
        "# # pretrained_embeddings[0] = 0\n",
        "# # word2vec = load_bin_vec('GoogleNews-vectors-negative300.bin', word_to_idx)\n",
        "# # for word, vector in word2vec.items():\n",
        "# #     pretrained_embeddings[word_to_idx[word]-1] = vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5pVuWDjRqYW",
        "colab_type": "code",
        "outputId": "a2b4e772-4be6-4eb2-8095-dca22f067c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!pip install glove_python\n",
        "from glove import Corpus, Glove"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: glove_python in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from glove_python) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWeos6bLjlP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def smote_read_sentences(path, sentence_separator):\n",
        "    filenames = os.listdir(path)\n",
        "    result = []\n",
        "    for filename in filenames:\n",
        "        with open(path + filename) as file:\n",
        "            lines = file.read()\n",
        "        lines = lines.split(sentence_separator)[:-1]\n",
        "        for line in lines:\n",
        "            l = []\n",
        "            for x in line.splitlines():\n",
        "                w = x.split(' ')\n",
        "                if w[0] == \"''\":\n",
        "                    w[0] = '\"'\n",
        "                w[0] = w[0].lower()\n",
        "                if len(w) == 2:\n",
        "                    l.append(np.array(w))\n",
        "            l = np.array(l)\n",
        "            result.append(l)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw8SLc9XjpPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = smote_read_sentences(\"SecureNLP/train/tokenized/\", \" \\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JISoWkEj_Gf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embed = [list(x[:, 0]) for x in train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j65Z9_RKcIl1",
        "colab_type": "code",
        "outputId": "6c06af1d-6a13-4f39-8541-acab2d45c85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "corpus = Corpus() \n",
        "corpus.fit(embed, window=10)\n",
        "glove = Glove(no_components=300, learning_rate=0.05)\n",
        "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
        "glove.add_dictionary(corpus.dictionary)\n",
        "glove.save('glove.model')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Performing 30 training epochs with 4 threads\n",
            "Epoch 0\n",
            "Epoch 1\n",
            "Epoch 2\n",
            "Epoch 3\n",
            "Epoch 4\n",
            "Epoch 5\n",
            "Epoch 6\n",
            "Epoch 7\n",
            "Epoch 8\n",
            "Epoch 9\n",
            "Epoch 10\n",
            "Epoch 11\n",
            "Epoch 12\n",
            "Epoch 13\n",
            "Epoch 14\n",
            "Epoch 15\n",
            "Epoch 16\n",
            "Epoch 17\n",
            "Epoch 18\n",
            "Epoch 19\n",
            "Epoch 20\n",
            "Epoch 21\n",
            "Epoch 22\n",
            "Epoch 23\n",
            "Epoch 24\n",
            "Epoch 25\n",
            "Epoch 26\n",
            "Epoch 27\n",
            "Epoch 28\n",
            "Epoch 29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsGi0VqpkhfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(glove.word_vectors[glove.dictionary['malware']])\n",
        "#emb = glove.word_vectors[glove.dictionary[word]]\n",
        "pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(text_field.vocab), 300))\n",
        "pretrained_embeddings[0]=0\n",
        "for word,index in glove.dictionary.items():\n",
        "  pretrained_embeddings[index]=glove.word_vectors[glove.dictionary[word]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "datrVjmKdE7Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV2zRZ0kdHXT",
        "colab_type": "code",
        "outputId": "3ae2a735-870d-42bb-cd07-dc036c761276",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "model.embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n",
        "# model.embeddings.weight.data = text_field.vocab.vectors\n",
        "# model.embeddings.embed.weight.requires_grad = False\n",
        "best_model = model\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_function = nn.NLLLoss()\n",
        "next(best_model.parameters()).is_cuda"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQz0x3yJmWsj",
        "colab_type": "code",
        "outputId": "a5ec89b2-5e20-4846-db61-6f17d71426a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print('Training...')\n",
        "out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
        "print(\"Writing to {}\\n\".format(out_dir))\n",
        "if not os.path.exists(out_dir):\n",
        "    os.makedirs(out_dir)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Writing to /content/runs/1580971258\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20N52pYUmuXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y7QwcwSmiRJ",
        "colab_type": "code",
        "outputId": "4d56bc44-cf8d-4200-89b4-5758b1909e3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(next(model.parameters()).is_cuda)\n",
        "    avg_loss, acc = train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch)\n",
        "    tqdm.write('Train: loss %.2f acc %.1f' % (avg_loss, acc*100))\n",
        "    dev_acc,pred_dev,truth_dev = evaluate(model, dev_iter, loss_function, 'Dev')\n",
        "    if dev_acc > best_dev_acc:\n",
        "        if best_dev_acc > 0:\n",
        "            os.system('rm '+ out_dir + '/best_model' + '.pth')\n",
        "        best_dev_acc = dev_acc\n",
        "        best_model = model\n",
        "        torch.save(best_model.state_dict(), out_dir + '/best_model' + '.pth')\n",
        "        # evaluate on test with the best dev performance model\n",
        "test_acc,pred_test, truth_test = evaluate(best_model, test_iter, loss_function, 'Test')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train epoch 1:   0%|          | 0/1885 [00:00<?, ?it/s]/content/bilstm.py:34: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  log_probs = F.log_softmax(y)\n",
            "Train epoch 1:   1%|          | 14/1885 [00:00<00:13, 138.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 1: 100%|██████████| 1885/1885 [00:12<00:00, 155.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: loss 0.01 acc 99.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 2:   1%|          | 17/1885 [00:00<00:11, 164.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dev: loss 1.01 acc 83.6\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 2: 100%|██████████| 1885/1885 [00:11<00:00, 157.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: loss 0.00 acc 99.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 3:   1%|          | 16/1885 [00:00<00:12, 152.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dev: loss 1.00 acc 81.5\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 3: 100%|██████████| 1885/1885 [00:11<00:00, 157.41it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: loss 0.00 acc 99.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 4:   1%|          | 17/1885 [00:00<00:11, 165.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dev: loss 0.61 acc 87.5\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 4: 100%|██████████| 1885/1885 [00:11<00:00, 157.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: loss 0.01 acc 99.8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 5:   1%|          | 16/1885 [00:00<00:11, 155.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dev: loss 0.94 acc 81.9\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 5: 100%|██████████| 1885/1885 [00:12<00:00, 155.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: loss 0.00 acc 99.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 6:   1%|          | 16/1885 [00:00<00:11, 156.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dev: loss 1.17 acc 81.8\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 6: 100%|██████████| 1885/1885 [00:12<00:00, 156.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: loss 0.00 acc 99.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 7:   1%|          | 13/1885 [00:00<00:14, 125.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dev: loss 0.71 acc 80.1\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 7: 100%|██████████| 1885/1885 [00:12<00:00, 153.64it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: loss 0.00 acc 99.9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 8:   1%|          | 15/1885 [00:00<00:13, 141.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Dev: loss 0.99 acc 84.5\n",
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch 8: 100%|██████████| 1885/1885 [00:11<00:00, 157.19it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train: loss 0.00 acc 100.0\n",
            "Dev: loss 1.28 acc 82.5\n",
            "Test: loss 2.12 acc 71.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOLS_puQpAqU",
        "colab_type": "code",
        "outputId": "ff305673-a2bb-4b6e-efba-ff50843ae28f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(torch.__version__)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTF0pY1YtXz7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9bd975f5-3fd7-46a6-b32a-c06e3df8a32d"
      },
      "source": [
        "print(int(pred_test[0].item()))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjX6SJ3ZQPs2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=list()\n",
        "for obj in truth_test:\n",
        "  test.append(int(obj.item()))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10dxF737QtNz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_OUm52N1GLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file2 = codecs.open(\"task1.txt\",\"w\",\"utf-8\")\n",
        "pred=list()\n",
        "for obj in pred_test:\n",
        "  #sent=sent.encode('utf-8')\n",
        "  file2.write(str(int(obj.item())))\n",
        "  pred.append(int(obj.item()))\n",
        "  file2.write(\"\\n\")\n",
        "file2.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ7J5Srk6AAs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "473adeb8-068d-49d8-9958-d9455de1ec99"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(test, pred))\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.74      0.82       528\n",
            "           1       0.28      0.59      0.38        90\n",
            "\n",
            "    accuracy                           0.72       618\n",
            "   macro avg       0.60      0.66      0.60       618\n",
            "weighted avg       0.82      0.72      0.75       618\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jckPjP0TQ8GO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
